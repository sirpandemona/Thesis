{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.rcParams['text.usetex'] = True # Comment this line if no LaTeX installation is available\n",
    "matplotlib.rcParams['font.family'] = 'serif' # Comment this line if no LaTeX installation is available\n",
    "matplotlib.rcParams['text.latex.preamble']=[r'\\usepackage{amsmath}']\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from pyvis.network import Network\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "import math\n",
    "import dgl\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch; torch.set_default_dtype(torch.float64)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "#import Albertos lib\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.insert(1, 'C:\\\\Users\\\\vascodebruijn\\\\Documents\\\\GitHub\\\\graph-neural-networks')\n",
    "\n",
    "import Utils.graphTools as graphTools\n",
    "import Utils.dataTools\n",
    "import Utils.graphML as gml\n",
    "\n",
    "import Modules.architectures as archit\n",
    "import Modules.model as model\n",
    "import Modules.training as training\n",
    "import Modules.evaluation as evaluation\n",
    "import Modules.loss as loss\n",
    "\n",
    "\n",
    "from Utils.miscTools import writeVarValues\n",
    "from Utils.miscTools import saveSeed\n",
    "\n",
    "\n",
    "#import own stuff\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"\\\\Python\")\n",
    "import import_traces\n",
    "import markov_mapping\n",
    "import linkage_mapping\n",
    "\n",
    "sbox=(\n",
    "    0x63,0x7c,0x77,0x7b,0xf2,0x6b,0x6f,0xc5,0x30,0x01,0x67,0x2b,0xfe,0xd7,0xab,0x76,\n",
    "    0xca,0x82,0xc9,0x7d,0xfa,0x59,0x47,0xf0,0xad,0xd4,0xa2,0xaf,0x9c,0xa4,0x72,0xc0,\n",
    "    0xb7,0xfd,0x93,0x26,0x36,0x3f,0xf7,0xcc,0x34,0xa5,0xe5,0xf1,0x71,0xd8,0x31,0x15,\n",
    "    0x04,0xc7,0x23,0xc3,0x18,0x96,0x05,0x9a,0x07,0x12,0x80,0xe2,0xeb,0x27,0xb2,0x75,\n",
    "    0x09,0x83,0x2c,0x1a,0x1b,0x6e,0x5a,0xa0,0x52,0x3b,0xd6,0xb3,0x29,0xe3,0x2f,0x84,\n",
    "    0x53,0xd1,0x00,0xed,0x20,0xfc,0xb1,0x5b,0x6a,0xcb,0xbe,0x39,0x4a,0x4c,0x58,0xcf,\n",
    "    0xd0,0xef,0xaa,0xfb,0x43,0x4d,0x33,0x85,0x45,0xf9,0x02,0x7f,0x50,0x3c,0x9f,0xa8,\n",
    "    0x51,0xa3,0x40,0x8f,0x92,0x9d,0x38,0xf5,0xbc,0xb6,0xda,0x21,0x10,0xff,0xf3,0xd2,\n",
    "    0xcd,0x0c,0x13,0xec,0x5f,0x97,0x44,0x17,0xc4,0xa7,0x7e,0x3d,0x64,0x5d,0x19,0x73,\n",
    "    0x60,0x81,0x4f,0xdc,0x22,0x2a,0x90,0x88,0x46,0xee,0xb8,0x14,0xde,0x5e,0x0b,0xdb,\n",
    "    0xe0,0x32,0x3a,0x0a,0x49,0x06,0x24,0x5c,0xc2,0xd3,0xac,0x62,0x91,0x95,0xe4,0x79,\n",
    "    0xe7,0xc8,0x37,0x6d,0x8d,0xd5,0x4e,0xa9,0x6c,0x56,0xf4,0xea,0x65,0x7a,0xae,0x08,\n",
    "    0xba,0x78,0x25,0x2e,0x1c,0xa6,0xb4,0xc6,0xe8,0xdd,0x74,0x1f,0x4b,0xbd,0x8b,0x8a,\n",
    "    0x70,0x3e,0xb5,0x66,0x48,0x03,0xf6,0x0e,0x61,0x35,0x57,0xb9,0x86,0xc1,0x1d,0x9e,\n",
    "    0xe1,0xf8,0x98,0x11,0x69,0xd9,0x8e,0x94,0x9b,0x1e,0x87,0xe9,0xce,0x55,0x28,0xdf,\n",
    "    0x8c,0xa1,0x89,0x0d,0xbf,0xe6,0x42,0x68,0x41,0x99,0x2d,0x0f,0xb0,0x54,0xbb,0x16) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class signal_data(Utils.dataTools._dataForClassification):\n",
    "    \n",
    "    def __init__(self,x,y,G,nTrain,nValid,nTest):\n",
    "        super().__init__()\n",
    "        (A,V) = G\n",
    "        (N,_) = x.shape\n",
    "        self.adjacencyMatrix = A\n",
    "        self.nNodes = V\n",
    "        self.nTotal = N\n",
    "        self.nTrain = nTrain\n",
    "        self.nValid = nValid\n",
    "        self.nTest = nTest\n",
    "        assert nTrain+nValid+nTest <= self.nTotal, \"Issue with splitting the dataset in test and train\"\n",
    "        self.samples['train']['signals'] = x[0:nTrain, :]\n",
    "        self.samples['train']['targets'] = y[0:nTrain]\n",
    "        self.samples['valid']['signals'] = x[nTrain:nTrain+nValid, :]\n",
    "        self.samples['valid']['targets']=y[nTrain:nTrain+nValid]\n",
    "        self.samples['test']['signals'] = x[nTrain+nValid:nTrain+nValid+nTest, :]\n",
    "        self.samples['test']['targets'] =y[nTrain+nValid:nTrain+nValid+nTest]\n",
    "        self.astype(torch.float64)\n",
    "        self.expandDims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "Traceback (most recent call last):\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\Scripts\\tensorboard-script.py\", line 5, in <module>\n",
       "    from tensorboard.main import run_main\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\lib\\site-packages\\tensorboard\\main.py\", line 43, in <module>\n",
       "    from tensorboard import default\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\lib\\site-packages\\tensorboard\\default.py\", line 40, in <module>\n",
       "    from tensorboard.plugins.beholder import beholder_plugin_loader\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\lib\\site-packages\\tensorboard\\plugins\\beholder\\__init__.py\", line 18, in <module>\n",
       "    import tensorflow\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\n",
       "    from tensorflow_core import *\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 46, in <module>\n",
       "    from . _api.v2 import compat\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\__init__.py\", line 39, in <module>\n",
       "    from . import v1\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\__init__.py\", line 32, in <module>\n",
       "    from . import compat\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\__init__.py\", line 39, in <module>\n",
       "    from . import v1\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\v1\\__init__.py\", line 29, in <module>\n",
       "    from tensorflow._api.v2.compat.v1 import app\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\__init__.py\", line 39, in <module>\n",
       "    from . import v1\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\__init__.py\", line 32, in <module>\n",
       "    from . import compat\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\__init__.py\", line 39, in <module>\n",
       "    from . import v1\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\v1\\__init__.py\", line 667, in <module>\n",
       "    from tensorflow_estimator.python.estimator.api._v1 import estimator\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\__init__.py\", line 10, in <module>\n",
       "    from tensorflow_estimator._api.v1 import estimator\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\_api\\v1\\estimator\\__init__.py\", line 10, in <module>\n",
       "    from tensorflow_estimator._api.v1.estimator import experimental\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\_api\\v1\\estimator\\experimental\\__init__.py\", line 10, in <module>\n",
       "    from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\", line 33, in <module>\n",
       "    from tensorflow_estimator.python.estimator import estimator\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 53, in <module>\n",
       "    from tensorflow_estimator.python.estimator import util as estimator_util\n",
       "  File \"C:\\Users\\vascodebruijn\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py\", line 75, in <module>\n",
       "    class _DatasetInitializerHook(tf.compat.v1.train.SessionRunHook):\n",
       "AttributeError: module 'tensorflow' has no attribute 'compat'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph(x):\n",
    "    \"\"\"\n",
    "    Generates graph used for graph signal classification\n",
    "    Params:\n",
    "        x: Traces in np-format (num_traces*num_features)\n",
    "    Returns:\n",
    "        A: adjacency matrix representing the edges\n",
    "        V: number of vertixes (A=V*V)  \n",
    "    \"\"\"\n",
    "    \n",
    "    (_,V) = x.shape\n",
    "    A = seq_connection(x)\n",
    "    \n",
    "    return (A,V)\n",
    "    \n",
    "def seq_connection(x):\n",
    "    \"\"\"\n",
    "    Connects all nodes corresponding to temporal successive nodes\n",
    "    Params:\n",
    "        x: Traces in np-format (num_traces*num_features)\n",
    "    Out:\n",
    "        A: Adjacency matrix\n",
    "    \"\"\"\n",
    "    (_,N) = x.shape\n",
    "    A = np.zeros((N,N))\n",
    "    for i in range(N-1):\n",
    "        j= i+1\n",
    "        A[i][j] = 1\n",
    "        A[j][i] = 1\n",
    "    return A\n",
    "\n",
    "def corr_tresh_connection(x,c):\n",
    "    \"\"\"\n",
    "    Connects nodes using Pearson Correlation as treshold value\n",
    "    Params:\n",
    "        x: Traces in np-format (num_traces*num_features)\n",
    "        c: treshold value\n",
    "    Out:\n",
    "        A: Adjacency matrix\n",
    "    \"\"\"\n",
    "    (_,N) = x.shape\n",
    "    A = np.zeros((N,N))\n",
    "    for i in range (N):\n",
    "        for j in range(i,N):\n",
    "            v_i= x[:,i]\n",
    "            v_j= x[:,j]\n",
    "            (corr,_) = scipy.stats.pearsonr(v_i, v_j)\n",
    "            if(corr >= c):\n",
    "                A[i,j] = 1\n",
    "                A[j,i] = 1\n",
    "    return A\n",
    "\n",
    "def corr_knn_connection(x,k):\n",
    "    \"\"\"\n",
    "    Connects nodes using Pearson Correlation with their K closest neighbours\n",
    "    Params:\n",
    "        x: Traces in np-format (num_traces*num_features)\n",
    "        k: amount of neighbours\n",
    "    Out:\n",
    "        A: Adjacency matrix\n",
    "    \"\"\"\n",
    "    (N,f) = x.shape\n",
    "    A = np.zeros((N,N))\n",
    "    C = np.zeros((N,N))\n",
    "    #put all correlations row-wise in a matrix\n",
    "    for i in range (N):\n",
    "        v_i= x[:,i]\n",
    "        for j in range(i,N):\n",
    "            v_j= x[:,j]\n",
    "            (corr,_) = scipy.stats.pearsonr(v_i, v_j)\n",
    "            C[i,j] = corr\n",
    "            C[j,i] = corr\n",
    "        #when a row is full, select the k highest values         \n",
    "        c_i = C[i,:]\n",
    "        sort_idx = np.argsort(c_i)\n",
    "        top = sort_idx[0:k]\n",
    "        A[i, top] =1\n",
    "    return A    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-be7a892a61ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[0mtrainingOptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[0mthisTrainVars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEdgeNetGNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrainingOptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\graph-neural-networks\\Modules\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data, nEpochs, batchSize, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\graph-neural-networks\\Modules\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                 \u001b[0mlossValueTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcostValueTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeElapsed\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthisBatchIndices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\graph-neural-networks\\Modules\\training.py\u001b[0m in \u001b[0;36mtrainBatch\u001b[1;34m(self, thisBatchIndices)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;31m# Obtain the output of the GNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[0myHatTrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marchit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;31m# Compute loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\graph-neural-networks\\Modules\\architectures.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1935\u001b[0m         \u001b[1;31m# (the GNN and the MLP) and returns only the MLP output in the proper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1936\u001b[0m         \u001b[1;31m# forward function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1937\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitForward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1938\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1939\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\graph-neural-networks\\Modules\\architectures.py\u001b[0m in \u001b[0;36msplitForward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# B x F x N\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1922\u001b[0m         \u001b[1;31m# Let's call the graph filtering layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEVGFL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1924\u001b[0m         \u001b[1;31m# Flatten the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1925\u001b[0m         \u001b[0myFlat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\graph-neural-networks\\Utils\\graphML.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1626\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1627\u001b[0m         \u001b[1;31m# x should be of shape batchSize x dimNodeSignals x nInputNodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1628\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnInputNodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1629\u001b[0m         \u001b[1;31m# Check that there are at least the same number of nodes that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m         \u001b[1;31m# we will keep (otherwise, it would be unpooling, instead of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "(traces, keys) = import_traces.get_DPA_traces()\n",
    "G = generate_graph(traces)\n",
    "(A,V) = G\n",
    "data = signal_data(traces.copy(),keys.copy(),G,8000,1000,1000 )\n",
    "n = len(keys)\n",
    "nFeatureBank = 1\n",
    "nClasses = 9\n",
    "k = 3\n",
    "\n",
    "dimNodeSignals =[1, nFeatureBank, nFeatureBank]\n",
    "dimLayersMLP= [nClasses]\n",
    "nShiftTaps =[k, k]\n",
    "nFilterNodes = [n, n]\n",
    "bias = False \n",
    "nonlinearity = nn.ReLU\n",
    "nSelectedNodes= [1, 1] \n",
    "poolingSize=[1, 1]\n",
    "GSO = A\n",
    "\n",
    "EdgeNet = archit.EdgeVariantGNN(dimNodeSignals, nShiftTaps,nFilterNodes,bias,nonlinearity,nSelectedNodes,Utils.graphML.NoPool,poolingSize,dimLayersMLP, GSO)\n",
    "\n",
    "lossFunction = nn.CrossEntropyLoss\n",
    "optimAlg = 'ADAM'\n",
    "learningRate = 0.001\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "trainer = training.Trainer\n",
    "evaluator = evaluation.evaluate\n",
    "thisOptim = optim.Adam(EdgeNet.parameters(), lr = learningRate, betas = (beta1,beta2))\n",
    "useGPU = False\n",
    "\n",
    "if useGPU and torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "EdgeNetGNN = model.Model(EdgeNet,\n",
    "                     lossFunction(),\n",
    "                     thisOptim,\n",
    "                     trainer,\n",
    "                     evaluator,\n",
    "                     device,\n",
    "                     \"EdgeNet\",\n",
    "                     'test') \n",
    "\n",
    "nEpochs = 100 # Number of epochs\n",
    "batchSize = 1 # Batch size\n",
    "validationInterval = 20 # How many training steps to do the validation\n",
    "trainingOptions = {}\n",
    "\n",
    "thisTrainVars = EdgeNetGNN.train(data, nEpochs, batchSize, **trainingOptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
